import{_ as h}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as m,b as e,t as g,e as n,n as p,g as c,w as t,d as a,f as i,r,o as b}from"./app-BgNevrm5.js";const f={},v={id:"frontmatter-title-관련",tabindex:"-1"},y={class:"header-anchor",href:"#frontmatter-title-관련"},w={class:"table-of-contents"},k=e("hr",null,null,-1),L=e("p",null,"If you’re an aspiring AI professional, becoming an LLM engineer offers an exciting and promising career path.",-1),_=e("p",null,"But where should you start? What should your trajectory look like? How should you learn?",-1),T={href:"https://dswharshit.medium.com/roadmap-to-become-an-ai-engineer-roadmap-6d9558d970cf",target:"_blank",rel:"noopener noreferrer"},j={href:"https://dswharshit.medium.com/roadmap-to-become-an-ai-engineer-roadmap-6d9558d970cf",target:"_blank",rel:"noopener noreferrer"},A=i('<div class="hint-container important"><p class="hint-container-title">The Best Way to Learn  is to  BUILD!</p><blockquote><p>As Andrej Karpathy puts it:</p><figure><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727441366598/07d24597-c31d-45b5-a99c-fbb485ce3459.png" alt="Karpathy&#39;s message on how to become an expert at a thing" tabindex="0" loading="lazy"><figcaption>Karpathy&#39;s message on how to become an expert at a thing</figcaption></figure></blockquote></div><p>Andrej emphasizes that you should build concrete projects, and explain everything you learn in your own words. (He also instructs us to only compare ourselves to a younger version of ourselves – never to others.)</p><p>And I agree – building projects is the best way to not just learn but really grok these concepts. It will further sharpen the skills you’re learning to think about cutting edge use cases.</p><p>But the main challenge with this learning philosophy is that good projects can be hard to find.</p><p>And that’s the problem I am trying to resolve. I want to help people, including myself, discover and build practical and real-world projects that help you develop skills that are worth showcasing in your portfolio.</p><hr><h2 id="what-should-be-your-first-project" tabindex="-1"><a class="header-anchor" href="#what-should-be-your-first-project"><span>What Should Be Your First Project?</span></a></h2><p>If you’re a beginner who knows basic to intermediate programming, your initial projects should showcase that you can comfortably build applications with LLMs.</p><p>They should demonstrate that:</p><ul><li>you know what APIs are</li><li>you know how to consume them</li><li>you know how to build products that people actually want to use</li></ul><p>Building a chatbot provides a great starting point, but at this point everyone has developed one. And there are many solutions for easy Streamlit based prototypes. So, you need to develop something that’s actually usable and has the potential to reach a wider audience.</p><p>I’d suggest building a chatbot for WhatsApp or Discord or Telegram. Build a chatbot which solves a problem people struggle with, a problem that companies have started to build solutions for.</p><p>If I had to pick a good and, arguably, the most common AI project that every company has started to work on, it would be RAG-powered chatbots.</p><p>But before you get to building RAG-powered bots, you should start building something slightly more basic but practical with LLMs.</p><p>To kick things off, let’s start by building a YouTube Summariser.</p><hr><h2 id="project-1-summarise-youtube-videos" tabindex="-1"><a class="header-anchor" href="#project-1-summarise-youtube-videos"><span>Project #1: Summarise YouTube Videos</span></a></h2><p>We’ll build the first part of this project in this tutorial: the core functionality of a YouTube video summariser tool.</p><figure><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727441993970/d318b7d9-37d5-4e93-a862-4d8c6e23886b.png" alt="Wiplane&#39;s project on building Youtube summariser whatsapp chatbot" tabindex="0" loading="lazy"><figcaption>Wiplane&#39;s project on building Youtube summariser whatsapp chatbot</figcaption></figure><p>Our bot will:</p><ul><li>Receive the YouTube URL.</li><li>Validate if the URL is correct.</li><li>Retrieve the transcript of the video</li><li>Use an LLM to analyze and summarize the video’s content.</li><li>Return the summary to the user.</li></ul><h3 id="setup-and-requirements" tabindex="-1"><a class="header-anchor" href="#setup-and-requirements"><span>Setup and Requirements</span></a></h3><p>For this project, we’ll code the core functionality in a Jupyter Notebook using the following Python packages:</p><ul><li><code>langchain-together</code> — for the LLM using the LangChain &lt;&gt; Together AI integration</li><li><code>langchain-community</code> — for specific data loaders</li><li><code>langchain</code> — for programming with LLMs</li><li><code>pytube</code> — for fetching video info</li><li><code>youtube-transcript-api</code> — for youtube video transcript</li></ul>',24),x={href:"https://together.ai/",target:"_blank",rel:"noopener noreferrer"},q=i(`<p><strong>Together AI</strong> is a cloud platform that offers the open source models as inference APIs. without worrying about the underlying infrastructure.</p><p>Let’s start by installing these:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">pip <span class="token function">install</span> —upgrade —quiet langchain</span>
<span class="line">pip <span class="token function">install</span> —quiet langchain-community</span>
<span class="line">pip <span class="token function">install</span> —upgrade —quiet langchain-together</span>
<span class="line">pip <span class="token function">install</span> youtube_transcript_api</span>
<span class="line">pip <span class="token function">install</span> pytube</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Now let’s set up our LLM:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment">## setting up the language model</span></span>
<span class="line"><span class="token keyword">from</span> langchain_together <span class="token keyword">import</span> ChatTogether</span>
<span class="line"><span class="token keyword">import</span> api_key</span>
<span class="line"></span>
<span class="line">llm <span class="token operator">=</span> ChatTogether<span class="token punctuation">(</span>api_key<span class="token operator">=</span>api_key<span class="token punctuation">.</span>api<span class="token punctuation">,</span>temperature<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> </span>
<span class="line">                    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The next step is to process the YouTube videos as a data source. For this we’ll need to understand the concept of document loaders.</p><h3 id="introduction-to-document-loaders" tabindex="-1"><a class="header-anchor" href="#introduction-to-document-loaders"><span>Introduction to Document Loaders</span></a></h3><p>Document loaders provide a unified interface to load data from various sources into a standardized Document format.</p>`,8),P=e("li",null,"They automatically extract and attach relevant metadata to the loaded content.",-1),I=e("li",null,"The metadata can include source information, timestamps, or other contextual data that can be valuable for downstream processing.",-1),M={href:"https://python.langchain.com/docs/how_to/#document-loaders",target:"_blank",rel:"noopener noreferrer"},S=i(`<figure><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727441974919/e979be2a-c1d8-4936-aa45-58d909855ace.png" alt="LangChain supports different types of document loaders" tabindex="0" loading="lazy"><figcaption>LangChain supports different types of document loaders</figcaption></figure><h4 id="categories-of-document-loaders" tabindex="-1"><a class="header-anchor" href="#categories-of-document-loaders"><span>Categories of Document Loaders</span></a></h4><p>Document loaders in LangChain can be broadly categorized into two types:</p><h5 id="_1-file-type-based-loaders" tabindex="-1"><a class="header-anchor" href="#_1-file-type-based-loaders"><span>1. File Type-Based Loaders</span></a></h5><ul><li>Parse and load documents based on specific file formats</li><li>Examples include: CSV, PDF, HTML, Markdown</li></ul><h5 id="_2-data-source-based-loaders" tabindex="-1"><a class="header-anchor" href="#_2-data-source-based-loaders"><span>2. Data Source-Based Loaders</span></a></h5><ul><li>Retrieve data from various external sources</li><li>Load the data into Document objects</li><li>Examples include: YouTube, Wikipedia, GitHub</li></ul><h4 id="integration-capabilities" tabindex="-1"><a class="header-anchor" href="#integration-capabilities"><span>Integration Capabilities</span></a></h4><ul><li>LangChain’s document loaders can integrate with almost any file format you might need.</li><li>They also support many third-party data sources.</li></ul><p>For our project, we’ll use the YoutubeLoader to get the transcripts in the required format.</p><h4 id="youtubeloader-from-langchain-to-get-transcript" tabindex="-1"><a class="header-anchor" href="#youtubeloader-from-langchain-to-get-transcript"><span>YoutubeLoader from LangChain to Get Transcript:</span></a></h4><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment">## import the youtube documnent loader from LangChain</span></span>
<span class="line"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> YoutubeLoader</span>
<span class="line"></span>
<span class="line">video_url <span class="token operator">=</span> <span class="token string">&#39;https://youtu.be/gaWxyWwziwE&#39;</span></span>
<span class="line">loader <span class="token operator">=</span> YoutubeLoader<span class="token punctuation">.</span>from_youtube_url<span class="token punctuation">(</span>video_url<span class="token punctuation">,</span> add_video_info<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></span>
<span class="line">data <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="process-the-youtube-transcript" tabindex="-1"><a class="header-anchor" href="#process-the-youtube-transcript"><span>Process the YouTube Transcript</span></a></h3><ul><li>Display raw transcript content</li><li>Use the LLM to summarize and extract key points from the transcript:</li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># show the extracted page content</span></span>
<span class="line">data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>The <code>page_content</code> attribute contains the complete transcript as shown in the output below:</p><figure><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727441916343/b834abbf-f4d5-4464-a421-257ef95fcbd1.png" alt="Youtube video transcript from the youtube loader" tabindex="0" loading="lazy"><figcaption>Youtube video transcript from the youtube loader</figcaption></figure><p>Now that we have the transcript, we simply need to pass this to the LLM we configured above along with the prompt to summarise.</p><p>First, let’s understand a simple method:</p><p>Langchain offers the <code>invoke()</code> method to which you need to pass the system message and the user or human message.</p><p>The system message is essentially the instructions for the LLM on how it is supposed to process the human request.</p><p>And the human message is simply what we want the LLM to do.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># This code creates a list of messages for the language model:</span></span>
<span class="line"><span class="token comment"># 1. A system message with instructions on how to summarize the video transcript</span></span>
<span class="line"><span class="token comment"># 2. A human message containing the actual video transcript</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># The messages are then passed to the language model (llm) for processing</span></span>
<span class="line"><span class="token comment"># The model&#39;s response is stored in the &#39;ai_msg&#39; variable and returned</span></span>
<span class="line"></span>
<span class="line">messages <span class="token operator">=</span> <span class="token punctuation">[</span></span>
<span class="line">    <span class="token punctuation">(</span></span>
<span class="line">        <span class="token string">&quot;system&quot;</span><span class="token punctuation">,</span> </span>
<span class="line">        <span class="token triple-quoted-string string">&quot;&quot;&quot;Read through the entire transcript carefully.</span>
<span class="line">            Provide a concise summary of the video&#39;s main topic and purpose.</span>
<span class="line">            Extract and list the five most interesting or important points from the transcript. For each point: State the key idea in a clear and concise manner.</span>
<span class="line"></span>
<span class="line">        - Ensure your summary and key points capture the essence of the video without including unnecessary details.</span>
<span class="line">        - Use clear, engaging language that is accessible to a general audience.</span>
<span class="line">        - If the transcript includes any statistical data, expert opinions, or unique insights, prioritize including these in your summary or key points.&quot;&quot;&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">(</span><span class="token string">&quot;human&quot;</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">]</span></span>
<span class="line">ai_msg <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span></span>
<span class="line">ai_msg</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>But this method won’t work when you have more variables and when you want a more dynamic solution.</p><h4 id="for-this-langchain-offers-prompttemplate" tabindex="-1"><a class="header-anchor" href="#for-this-langchain-offers-prompttemplate"><span>For this, LangChain offers PromptTemplate</span></a></h4><p>A PromptTemplate in LangChain is a powerful tool that helps in creating dynamic prompts for large language models (LLMs). It allows you to define a template with placeholders for variables that can be filled in with actual values at runtime.</p><p>This helps in managing and reusing prompts efficiently, ensuring consistency and reducing the likelihood of errors in prompt creation.</p><p>A PromptTemplate consists of:</p><ul><li><strong>Template String</strong>: The actual prompt text with placeholders for variables.</li><li><strong>Input Variables</strong>: A list of variables that will be replaced in the template string at runtime.</li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># Set up a prompt template for summarizing a video transcript using LangChain</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Import necessary classes from LangChain</span></span>
<span class="line"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate</span>
<span class="line"><span class="token keyword">from</span> langchain <span class="token keyword">import</span> LLMChain</span>
<span class="line"></span>
<span class="line"><span class="token comment"># Define a PromptTemplate for summarizing video transcripts</span></span>
<span class="line"><span class="token comment"># The template includes instructions for the AI model on how to process the transcript</span></span>
<span class="line">product_description_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span></span>
<span class="line">    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;video_transcript&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    template<span class="token operator">=</span><span class="token triple-quoted-string string">&quot;&quot;&quot;</span>
<span class="line">    Read through the entire transcript carefully.</span>
<span class="line">            Provide a concise summary of the video&#39;s main topic and purpose.</span>
<span class="line">            Extract and list the five most interesting or important points from the transcript. </span>
<span class="line">            For each point: State the key idea in a clear and concise manner.</span>
<span class="line"></span>
<span class="line">        - Ensure your summary and key points capture the essence of the video without including unnecessary details.</span>
<span class="line">        - Use clear, engaging language that is accessible to a general audience.</span>
<span class="line">        - If the transcript includes any statistical data, expert opinions, or unique insights, </span>
<span class="line">        prioritize including these in your summary or key points.</span>
<span class="line"></span>
<span class="line">    Video transcript: {video_transcript}    &quot;&quot;&quot;</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="how-to-use-llmchain-lcel-for-summarization" tabindex="-1"><a class="header-anchor" href="#how-to-use-llmchain-lcel-for-summarization"><span>How to Use LLMChain / LCEL for Summarization</span></a></h3><p>A chain is a sequence of steps that consists of a language model, PromptTemplate, and an optional output parser.</p><ul><li>Create an LLMChain with the custom prompt template</li><li>Generate a summary of the video transcript using the chain</li></ul><p>Here, we are using LLMChain but you can also use LangChain Expression Language as well to do this:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment">## invoke the chain with the video transcript </span></span>
<span class="line">chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>product_description_template<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Run the chain with the provided product details</span></span>
<span class="line">summary <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">    <span class="token string">&quot;video_transcript&quot;</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content</span>
<span class="line"><span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>This will give you the summary object which has the text attribute that contains the response in markdown format.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">summary<span class="token punctuation">[</span><span class="token string">&#39;text&#39;</span><span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>The raw response will look like this:</p><figure><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727441806141/be122b5b-6774-46be-92ab-1f9e651b5045.png" alt="summary response from simple LLM chain" tabindex="0" loading="lazy"><figcaption>summary response from simple LLM chain</figcaption></figure><p>To see the Markdown formatted response:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Markdown<span class="token punctuation">,</span> display</span>
<span class="line"></span>
<span class="line">display<span class="token punctuation">(</span>Markdown<span class="token punctuation">(</span>summary<span class="token punctuation">[</span><span class="token string">&#39;text&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>And there you go:</p><figure><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727441776170/98223339-03d2-483c-84ef-9400d2eb33f2.png" alt="Structure summary display using Markdown function" tabindex="0" loading="lazy"><figcaption>Structure summary display using Markdown function</figcaption></figure><p>So, the core functionality of our YouTube summariser is now working.</p><p>But this is working in your Jupyter Notebook, to make it more accessible, we’d need to get this functionality deployed on WhatsApp.</p><h3 id="how-to-serve-the-yt-summariser-on-whatsapp" tabindex="-1"><a class="header-anchor" href="#how-to-serve-the-yt-summariser-on-whatsapp"><span>How to serve the YT summariser on WhatsApp</span></a></h3><figure><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727421384448/cd7f0f37-f25b-4b46-a4a9-0bcd5bf0f0fd.png" alt="Establishing connection between youtube and flask server using Twilio" tabindex="0" loading="lazy"><figcaption>Establishing connection between youtube and flask server using Twilio</figcaption></figure><p>For this, we’d need to serve our YT summarisation functionality as an API endpoint for which we are going to use Flask. You can also use FastAPI.</p><p>Now we’ll turn all the code in the Jupyter notebook into functions. So, add a function to check if it is a valid youtube URL, then define the <code>summarise</code> function that is basically a compilation of what we wrote in the Jupyter notebook.</p><p>You can configure our endpoint in the following manner:</p><pre><code>@app.route(&#39;/summary&#39;, methods=[&#39;POST&#39;])
def summary():
    url = request.form.get(&#39;Body&#39;)  # Get the JSON data from the request body
    print(url)
    if is_youtube_url(url):
        response = summarise(url)
    else:
        response = &quot;please check if this is a correct youtube video url&quot;
    print(response)
    resp = MessagingResponse()
    msg = resp.message()
    msg.body(response)
    return str(resp)
</code></pre><p>Once your <code>app.py</code> is ready with your Flask API, run the Python script, and you should have your server running locally on your system.</p><p>The next step is to make your local server connect with WhatsApp, and that’s where we’ll use Twilio.</p>`,53),C={href:"https://twilio.com/docs/whatsapp/quickstart/python",target:"_blank",rel:"noopener noreferrer"},B=e("p",null,"I got the connection established:",-1),z=e("figure",null,[e("img",{src:"https://cdn.hashnode.com/res/hashnode/image/upload/v1727422495235/4a60a190-2d57-4726-be7c-1e062c4528e5.png",alt:"Configure twilio sandbox settings",tabindex:"0",loading:"lazy"}),e("figcaption",null,"Configure twilio sandbox settings")],-1),W=e("p",null,"Now, we can start testing our WhatsApp bot:",-1),R=e("figure",null,[e("img",{src:"https://cdn.hashnode.com/res/hashnode/image/upload/v1727422721636/339fd977-6b63-4f57-ba40-e677c32e1814.png",alt:"Summariser chatbot screenshot",tabindex:"0",loading:"lazy"}),e("figcaption",null,"Summariser chatbot screenshot")],-1),Y=e("p",null,"Amazing!",-1),H={href:"https://wiplane.com/whatsapp-chatbot",target:"_blank",rel:"noopener noreferrer"},D=e("strong",null,"Building LLM-powered WhatsApp Chatbots",-1),E=i('<p>It’s a <strong>3-project course</strong> that contains two other more complex projects. I’ll give you a brief summary of those other projects here so you can try them out for yourselves. And if you’re interested, you can check out the course as well.</p><hr><h2 id="project-2-—-build-a-bot-that-can-handle-different-types-of-user-queries" tabindex="-1"><a class="header-anchor" href="#project-2-—-build-a-bot-that-can-handle-different-types-of-user-queries"><span>Project #2 — Build a Bot that Can Handle Different Types of User Queries</span></a></h2><blockquote><p>https://wiplane.com/whatsapp-chatbot</p></blockquote><p>This bot acts as a customer service representative for an airline. It can answer questions related to flight status, baggage inquiries, ticket booking, and more. It uses Langchain’s Router and LLM models to dynamically generate responses based on the user’s input.</p><ul><li>Different prompt templates are defined for various customer queries, such as flight status, baggage inquiries, and complaints.</li><li>Based on the query, the router selects the appropriate template and generates a response.</li><li>Twilio then sends the response back to the WhatsApp chat.</li></ul><figure><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727441691086/54bcc4a9-8e04-4509-a361-ee4eb15bca08.png" alt="Wiplane&#39;s project 2 - Airline customer support to handle different types of queries" tabindex="0" loading="lazy"><figcaption>Wiplane&#39;s project 2 - Airline customer support to handle different types of queries</figcaption></figure><hr><h2 id="project-3-—-rag-powered-support-bot" tabindex="-1"><a class="header-anchor" href="#project-3-—-rag-powered-support-bot"><span>Project #3 — RAG-Powered Support Bot</span></a></h2><blockquote><p>https://wiplane.com/whatsapp-chatbot</p></blockquote><p>This chatbot answers questions related to airline services using a document-based system. The document is converted into embeddings, which are then queried using Langchain’s RAG system to generate responses. Companies want developers these days who have these skills, so this is an especially practical project.</p><ul><li>The guidelines/rules document is embedded using FAISS and HuggingFace models.</li><li>When a user submits a question, the RAG system retrieves relevant information from the document.</li><li>The system then generates a response using a pre-trained LLM and sends it back via Twilio.</li></ul><figure><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727441686023/fe55ec78-96dd-42bd-aeae-ceaad24aae44.png" alt="Wiplane&#39;s project 3 - RAG powered support bot" tabindex="0" loading="lazy"><figcaption>Wiplane&#39;s project 3 - RAG powered support bot</figcaption></figure><p>These 3 projects will get you started so you can continue experimenting and learning more about AI engineering.</p><figure><a href="https://wiplane.com/whatsapp-chatbot" target="_blank" rel="noopener noreferrer"><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1727306395800/82bf4b68-a79b-4f40-b4fe-61f99fa445ab.png" alt="Wiplane&#39;s 3 project course on building LLM powered whatsapp chatbots" tabindex="0" loading="lazy"></a><figcaption>Wiplane&#39;s 3 project course on building LLM powered whatsapp chatbots</figcaption></figure><p>Customer Support is the most funded category in AI because it reduces the cost instantly if AI can handle communication with disgruntled users.</p><p>So, we build bots that can handle different types of queries, intelligent RAG powered bots which will have access to proprietary documents to provided up-to-date information to the users.</p>',17),F={href:"https://wiplane.com/whatsapp-chatbot",target:"_blank",rel:"noopener noreferrer"},U=i('<p>Check out the course preview here:</p><p>And to thank you for reading this guide, you can use the code FREECODECAMP to get a 20% discount on my course.</p><p>I want to make this affordably accessible for all those who are sincere about building with AI, so I’ve priced it affordably at $14.99 USD.</p><hr><h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion"><span>Conclusion</span></a></h2><p>In this tutorial, we focused on building a fun YouTube video summarizer tool that is served on WhatsApp.</p><p>The bot&#39;s core functionality includes:</p><ul><li>Receiving a YouTube URL</li><li>Validating the URL</li><li>Retrieving the video transcript</li><li>Using an LLM to summarize the content</li><li>Returning the summary to the user</li></ul><p>We used a number of Python packages including <code>langchain-together</code>, <code>langchain-community</code>, <code>langchain</code>, <code>pytube</code>, and <code>youtube-transcript-api</code>.</p><p>The project uses the Llama 3.1 model via Together AI&#39;s API.</p><p>We built the core summarisation functionality using</p><ul><li>Using LangChain&#39;s <code>invoke()</code> method with system and human messages</li><li>Using PromptTemplate and LLMChain for more dynamic solutions</li></ul><p>To make the tool accessible via WhatsApp:</p><ul><li>The functionality is served as an API endpoint using Flask</li><li>Twilio is used to connect the local server with WhatsApp</li><li>A WhatsApp sandbox is used for testing the bot</li></ul><p>To continue building further projects, check out the course.</p><p>It is a beginner track course where you start from learning to build with LLMs, then apply those skills to build 3 different types of LLM applications. Not just that – you learn to serve your applications as WA chatbots.</p>',16);function G(d,V){const l=r("VPCard"),s=r("router-link"),u=r("SiteInfo"),o=r("FontIcon");return b(),m("div",null,[e("h1",v,[e("a",y,[e("span",null,g(d.$frontmatter.title)+" 관련",1)])]),n(l,p(c({title:"LLM > Article(s)",desc:"Article(s)",link:"/ai/llm/articles/README.md",logo:"/images/ico-wind.svg",background:"rgba(10,10,10,0.2)"})),null,16),n(l,p(c({title:"Python > Article(s)",desc:"Article(s)",link:"/programming/py/articles/README.md",logo:"/images/ico-wind.svg",background:"rgba(10,10,10,0.2)"})),null,16),e("nav",w,[e("ul",null,[e("li",null,[n(s,{to:"#what-should-be-your-first-project"},{default:t(()=>[a("What Should Be Your First Project?")]),_:1})]),e("li",null,[n(s,{to:"#project-1-summarise-youtube-videos"},{default:t(()=>[a("Project #1: Summarise YouTube Videos")]),_:1}),e("ul",null,[e("li",null,[n(s,{to:"#setup-and-requirements"},{default:t(()=>[a("Setup and Requirements")]),_:1})]),e("li",null,[n(s,{to:"#introduction-to-document-loaders"},{default:t(()=>[a("Introduction to Document Loaders")]),_:1})]),e("li",null,[n(s,{to:"#process-the-youtube-transcript"},{default:t(()=>[a("Process the YouTube Transcript")]),_:1})]),e("li",null,[n(s,{to:"#how-to-use-llmchain-lcel-for-summarization"},{default:t(()=>[a("How to Use LLMChain / LCEL for Summarization")]),_:1})]),e("li",null,[n(s,{to:"#how-to-serve-the-yt-summariser-on-whatsapp"},{default:t(()=>[a("How to serve the YT summariser on WhatsApp")]),_:1})])])]),e("li",null,[n(s,{to:"#project-2-—-build-a-bot-that-can-handle-different-types-of-user-queries"},{default:t(()=>[a("Project #2 — Build a Bot that Can Handle Different Types of User Queries")]),_:1})]),e("li",null,[n(s,{to:"#project-3-—-rag-powered-support-bot"},{default:t(()=>[a("Project #3 — RAG-Powered Support Bot")]),_:1})]),e("li",null,[n(s,{to:"#conclusion"},{default:t(()=>[a("Conclusion")]),_:1})])])]),k,n(u,{name:"How to Start Building Projects with LLMs",desc:"If you’re an aspiring AI professional, becoming an LLM engineer offers an exciting and promising career path. But where should you start? What should your trajectory look like? How should you learn? In one of my previous posts, I laid out the complet...",url:"https://freecodecamp.org/news/how-to-start-building-projects-with-llms/",logo:"https://cdn.freecodecamp.org/universal/favicons/favicon.ico",preview:"https://cdn.hashnode.com/res/hashnode/image/upload/v1727442031549/2b9f61f1-d25d-4c10-8a9e-c63fe7ee7cad.png"}),L,_,e("p",null,[a("In one of my "),e("a",T,[n(o,{icon:"fa-brands fa-medium"}),a("previous")]),a(),e("a",j,[n(o,{icon:"fa-brands fa-medium"}),a("posts")]),a(", I laid out the complete roadmap to become an AI / LLM Engineer. Reading this article will give you insights into the types of skills you’ll need to acquire and how to start learning.")]),A,e("p",null,[a("We’ll use the Llama 3.1 model offered as an API by "),e("a",x,[n(o,{icon:"fas fa-globe"}),a("Together AI")]),a(".")]),q,e("ul",null,[P,I,e("li",null,[a("LangChain offers loaders for CSV, PDF, HTML, JSON, and even specialized loaders for sources like YouTube transcripts or GitHub repositories, as listed in "),e("a",M,[n(o,{icon:"fa-brands fa-python"}),a("their integrations page")]),a(".")])]),S,e("p",null,[a("Twilio allows us to implement this handshake by offering a WhatsApp sandbox to test your bot. You can follow the steps in this guide "),e("a",C,[n(o,{icon:"fas fa-globe"}),a("here")]),a(" to build this connection.")]),B,z,W,R,Y,e("p",null,[a("I explain all the steps in detail in my project-based course on "),e("a",H,[n(o,{icon:"fas fa-globe"}),D]),a(".")]),E,e("p",null,[a("That’s why I created "),e("a",F,[n(o,{icon:"fas fa-globe"}),a("this project-based course")]),a(" to help you start building with LLMs.")]),U])}const J=h(f,[["render",G],["__file","how-to-start-building-projects-with-llms.html.vue"]]),K=JSON.parse('{"path":"/freecodecamp.org/how-to-start-building-projects-with-llms.html","title":"How to Start Building Projects with LLMs","lang":"en-US","frontmatter":{"lang":"en-US","title":"How to Start Building Projects with LLMs","description":"Article(s) > How to Start Building Projects with LLMs","icon":"fas fa-language","category":["Article(s)","AI","LLM","Python"],"tag":["blog","freecodecamp.org","ai","llm","python","py"],"head":[[{"meta":null},{"property":"og:title","content":"Article(s) > How to Start Building Projects with LLMs"},{"property":"og:description","content":"How to Start Building Projects with LLMs"},{"property":"og:url","content":"https://chanhi2000.github.io/bookshelf/freecodecamp.org/how-to-start-building-projects-with-llms.html"}],["meta",{"property":"og:url","content":"https://chanhi2000.github.io/bookshelf/freecodecamp.org/how-to-start-building-projects-with-llms.html"}],["meta",{"property":"og:site_name","content":"📚Bookshelf"}],["meta",{"property":"og:title","content":"How to Start Building Projects with LLMs"}],["meta",{"property":"og:description","content":"Article(s) > How to Start Building Projects with LLMs"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.hashnode.com/res/hashnode/image/upload/v1727442031549/2b9f61f1-d25d-4c10-8a9e-c63fe7ee7cad.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://cdn.hashnode.com/res/hashnode/image/upload/v1727442031549/2b9f61f1-d25d-4c10-8a9e-c63fe7ee7cad.png"}],["meta",{"name":"twitter:image:alt","content":"How to Start Building Projects with LLMs"}],["meta",{"property":"article:author","content":"Harshit Tyagi"}],["meta",{"property":"article:tag","content":"blog"}],["meta",{"property":"article:tag","content":"freecodecamp.org"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:tag","content":"llm"}],["meta",{"property":"article:tag","content":"python"}],["meta",{"property":"article:tag","content":"py"}],["meta",{"property":"article:published_time","content":"2024-09-30T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"How to Start Building Projects with LLMs\\",\\"image\\":[\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727441366598/07d24597-c31d-45b5-a99c-fbb485ce3459.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727441993970/d318b7d9-37d5-4e93-a862-4d8c6e23886b.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727441974919/e979be2a-c1d8-4936-aa45-58d909855ace.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727441916343/b834abbf-f4d5-4464-a421-257ef95fcbd1.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727441806141/be122b5b-6774-46be-92ab-1f9e651b5045.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727441776170/98223339-03d2-483c-84ef-9400d2eb33f2.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727421384448/cd7f0f37-f25b-4b46-a4a9-0bcd5bf0f0fd.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727422495235/4a60a190-2d57-4726-be7c-1e062c4528e5.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727422721636/339fd977-6b63-4f57-ba40-e677c32e1814.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727441691086/54bcc4a9-8e04-4509-a361-ee4eb15bca08.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727441686023/fe55ec78-96dd-42bd-aeae-ceaad24aae44.png\\",\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1727306395800/82bf4b68-a79b-4f40-b4fe-61f99fa445ab.png\\"],\\"datePublished\\":\\"2024-09-30T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Harshit Tyagi\\"}]}"]],"prev":"/ai/llm/articles/README.md","date":"2024-09-30T00:00:00.000Z","isOriginal":false,"author":"Harshit Tyagi","cover":"https://cdn.hashnode.com/res/hashnode/image/upload/v1727442031549/2b9f61f1-d25d-4c10-8a9e-c63fe7ee7cad.png"},"headers":[{"level":2,"title":"What Should Be Your First Project?","slug":"what-should-be-your-first-project","link":"#what-should-be-your-first-project","children":[]},{"level":2,"title":"Project #1: Summarise YouTube Videos","slug":"project-1-summarise-youtube-videos","link":"#project-1-summarise-youtube-videos","children":[{"level":3,"title":"Setup and Requirements","slug":"setup-and-requirements","link":"#setup-and-requirements","children":[]},{"level":3,"title":"Introduction to Document Loaders","slug":"introduction-to-document-loaders","link":"#introduction-to-document-loaders","children":[]},{"level":3,"title":"Process the YouTube Transcript","slug":"process-the-youtube-transcript","link":"#process-the-youtube-transcript","children":[]},{"level":3,"title":"How to Use LLMChain / LCEL for Summarization","slug":"how-to-use-llmchain-lcel-for-summarization","link":"#how-to-use-llmchain-lcel-for-summarization","children":[]},{"level":3,"title":"How to serve the YT summariser on WhatsApp","slug":"how-to-serve-the-yt-summariser-on-whatsapp","link":"#how-to-serve-the-yt-summariser-on-whatsapp","children":[]}]},{"level":2,"title":"Project #2 — Build a Bot that Can Handle Different Types of User Queries","slug":"project-2-—-build-a-bot-that-can-handle-different-types-of-user-queries","link":"#project-2-—-build-a-bot-that-can-handle-different-types-of-user-queries","children":[]},{"level":2,"title":"Project #3 — RAG-Powered Support Bot","slug":"project-3-—-rag-powered-support-bot","link":"#project-3-—-rag-powered-support-bot","children":[]},{"level":2,"title":"Conclusion","slug":"conclusion","link":"#conclusion","children":[]}],"git":{"contributors":[{"name":"chanhi2000","email":"chanhi2000@gmail.com","commits":2}]},"readingTime":{"minutes":9.48,"words":2843},"filePathRelative":"freecodecamp.org/how-to-start-building-projects-with-llms.md","localizedDate":"September 30, 2024","excerpt":"\\n","copyright":{"author":"Harshit Tyagi"}}');export{J as comp,K as data};
