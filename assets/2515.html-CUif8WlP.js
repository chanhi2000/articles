import{_ as p}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as m,b as e,t as h,e as i,n as f,g as u,w as a,d as t,f as l,r as s,o as y}from"./app-BgNevrm5.js";const w={},k={id:"frontmatter-title-관련",tabindex:"-1"},z={class:"header-anchor",href:"#frontmatter-title-관련"},b={class:"table-of-contents"},_=e("hr",null,null,-1),x=e("p",null,"쿠버네티스는 계속 고도화되고 있어서 이를 분석하고 조치하는 것은 다양한 기반 지식을 필요로 합니다. 작년에 이어 올해도 인기 있는 인공지능(AI, Artificial Intelligence)을 이용해서 쿠버네티스를 분석하고 이에 맞는 조치를 할 수 있습니다.",-1),I=e("ol",null,[e("li",null,"1년간의 변화"),e("li",null,"공개된 AI 제공자를 사용하는게 아닌 나만의 AI 제공자를 사용하는 법"),e("li",null,"K8sGPT의 미래 전망")],-1),A=e("img",{src:"https://yozm.wishket.com/media/news/2515/image4.png",alt:'K8sGPT 로고(출처: <FontIcon icon="iconfont icon-github"/>)',tabindex:"0",loading:"lazy"},null,-1),v={href:"https://github.com/k8sgpt-ai/k8sgpt",target:"_blank",rel:"noopener noreferrer"},G=e("code",null,"k8sgpt-ai/k8sgpt",-1),P=l('<hr><h2 id="_1년간의-변화" tabindex="-1"><a class="header-anchor" href="#_1년간의-변화"><span>1년간의 변화</span></a></h2><p>K8sGPT의 v0.0.1은 2023년 3월에 시작되었습니다. 그리고 이 글이 작성되는 2024년 3월 (그러고 보니 딱 1년이 지났네요?)의 버전은 v0.3.28이 되었습니다.</p><h3 id="다양한-서비스-제공자" tabindex="-1"><a class="header-anchor" href="#다양한-서비스-제공자"><span>다양한 서비스 제공자</span></a></h3><p>1년간의 주요한 변화 중 하나는 K8sGPT가 질의 구문을 요청할 수 있는 제공자(Provider)가 매우 많아졌다는 것입니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/1_iru0ARX.png" alt="K8sGPT의 인증을 통해서 서비스를 제공할 수 있는 API 리스트" tabindex="0" loading="lazy"><figcaption>K8sGPT의 인증을 통해서 서비스를 제공할 수 있는 API 리스트</figcaption></figure><p>v0.3.28에는 <code>googlevertexai</code>가 추가되었고, v0.3.27에는 <code>huggingface</code>가 추가되었습니다. 이러한 빠른 AI 서비스 제공자와의 통합을 통해서 성장 속도는 더더욱 가속화 되고 있습니다. 우선 간단하게 현재 상태를 점검해 보겠습니다. 점검을 위해서 구글클라우드플랫폼에서 제공하는 마이크로 서비스 아키텍처 앱인 “Online Boutine”를 배포하겠습니다.</p>',7),T=e("img",{src:"https://yozm.wishket.com/media/news/2515/image2.png",alt:'구글클라우드플랫폼에서 제공하는 “<FontIcon icon="iconfont icon-github"/>Online Boutine” 애플리케이션(출처 :<FontIcon icon="iconfont icon-github"/>Online Boutine)',tabindex:"0",loading:"lazy"},null,-1),L={href:"https://github.com/GoogleCloudPlatform/microservices-demo",target:"_blank",rel:"noopener noreferrer"},K={href:"https://github.com/GoogleCloudPlatform/microservices-demo",target:"_blank",rel:"noopener noreferrer"},B=l('<figure><img src="https://yozm.wishket.com/media/news/2515/2_NgxMTnp.png" alt="실행 결과는 다음과 같습니다." tabindex="0" loading="lazy"><figcaption>실행 결과는 다음과 같습니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2515/3.png" alt="배포가 끝났다면 이제 를 실행해서 나오는 결과를 통해서 현재 문제가 없는 상태인지 확인합니다." tabindex="0" loading="lazy"><figcaption>배포가 끝났다면 이제 <code>k8sgpt analyze</code>를 실행해서 나오는 결과를 통해서 현재 문제가 없는 상태인지 확인합니다.</figcaption></figure><div class="hint-container tip"><p class="hint-container-title">노트</p><p>설치는 <code>brew</code>, <code>rpm</code>, <code>deb</code> 등 다양한 방법을 제공합니다. 다음<a href="https://docs.k8sgpt.ai/getting-started/installation/" target="_blank" rel="noopener noreferrer">링크</a>에서 확인하세요)</p></div><p>현재는 문제가 없는 상태입니다. 따라서 AI가 문제를 분석할 수 있도록 문제를 만들어 봅시다. 예제로 괜찮은 문제는 서비스는 존재하지만 파드가 없는 상태입니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/4.png" alt="이 상태로 만들기 위해 frontend 애플리케이션을 으로 바꿔서 서비스를 받아줄 파드가 없는 상태로 만듭니다." tabindex="0" loading="lazy"><figcaption>이 상태로 만들기 위해 frontend 애플리케이션을 <code>0</code>으로 바꿔서 서비스를 받아줄 파드가 없는 상태로 만듭니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2515/5.png" alt="그리고 문제가 발생한 상태에서 다시 를 실행합니다." tabindex="0" loading="lazy"><figcaption>그리고 문제가 발생한 상태에서 다시 <code>k8sgpt analyze</code>를 실행합니다.</figcaption></figure><p>사실 아직까지는 AI의 도움을 받아서 분석한 상태는 아닙니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/6_2beWtS4.png" alt="따라서 AI의 도움을 받기 위해서  옵션과 를 추가 입력하고 결과를 확인합니다." tabindex="0" loading="lazy"><figcaption>따라서 AI의 도움을 받기 위해서 <code>--explain</code> 옵션과 <code>--backend openai</code>를 추가 입력하고 결과를 확인합니다.</figcaption></figure>',8),M={class:"hint-container tip"},O=e("p",{class:"hint-container-title"},"노트",-1),C=e("p",null,[t("기본 값이 "),e("code",null,"--backend openai"),t(" 입니다. 그리고 인증 절차는 이미 처리되었습니다.")],-1),R={href:"https://docs.k8sgpt.ai/reference/providers/backend/",target:"_blank",rel:"noopener noreferrer"},V={href:"https://cohere.com/",target:"_blank",rel:"noopener noreferrer"},S={href:"https://docs.k8sgpt.ai/reference/providers/backend/",target:"_blank",rel:"noopener noreferrer"},D=l('<figure><img src="https://yozm.wishket.com/media/news/2515/image3.png" alt="구글 AI 스튜디오" tabindex="0" loading="lazy"><figcaption>구글 AI 스튜디오</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2515/image1.png" alt="Cohere에서 제공하는 API 키" tabindex="0" loading="lazy"><figcaption>Cohere에서 제공하는 API 키</figcaption></figure><p>해당 설정을 완료했다면 이제 백엔드(Backend) 제공자를 google과 cohere로 변경하여 결괏값을 비교해 보도록 하겠습니다. 각 제공자마다 알려주는 방법과 내용은 유사하지만 문맥과 흐름은 다소 차이가 있는 것을 확인할 수 있습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/7.png" alt="백엔드를 google로 한 결과값" tabindex="0" loading="lazy"><figcaption>백엔드를 google로 한 결과값</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2515/8.png" alt="백엔드를 cohere로 한 결과값" tabindex="0" loading="lazy"><figcaption>백엔드를 cohere로 한 결과값</figcaption></figure><p>이렇게 영어로 나오는 결과는 아무래도 한국어보다는 불편합니다. 따라서 한국어로 어떻게 설명해 주는지 확인해 보기 위해 옵션<code>--language</code>를 사용합니다. 한국어 뿐만 아니라 스페인어, 프랑스어, 독일어, 이탈리아어, 포르투갈어, 네덜란드어, 러시아어, 중국어, 일본어를 제공합니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/9_kI0xqpR.png" alt="google 백엔드 상태에서 언어를 한국어로 선택한 결괏값" tabindex="0" loading="lazy"><figcaption>google 백엔드 상태에서 언어를 한국어로 선택한 결괏값</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2515/10.png" alt="cohere 백엔드 상태에서 언어를 한국어로 선택한 결괏값" tabindex="0" loading="lazy"><figcaption>cohere 백엔드 상태에서 언어를 한국어로 선택한 결괏값</figcaption></figure><p>위의 결괏값을 미루어보아 한국어와 같은 다른 언어를 사용하여 질의하는 경우 영어의 결과를 단순히 번역하는 것이 아니라 새로운 결과를 만들어 내려고 하며, 아무래도 한국어를 기반으로 좀 더 많은 데이터를 학습한 것으로 알려져 있는 google이 더 자연스러운 응답을 보여주는 것으로 확인되었습니다. 이와 같은 분석 외에도 인공지능이 현재처럼 유명해진 계기가 된 대화(Chat)를 기반으로 진행할 수도 있습니다.</p><hr><h2 id="상호-작용-interactive-모드" tabindex="-1"><a class="header-anchor" href="#상호-작용-interactive-모드"><span>상호 작용 (Interactive) 모드</span></a></h2><p>상호 작용 모드는 v0.3.26(출시일: 2024년 1월)부터 지원하기 시작했습니다. 이는 ChatGPT와 같이 대화를 기반으로 좀 더 상세한 내용을 질의하거나 연관된 내용을 물어보기 위해서 사용될 수 있습니다.</p><p>현재 사용 가능한 google과 cohere에 <code>--interative</code> 옵션을 써서 관련 내용을 물어보도록 하겠습니다. 가장 처음으로 google 백엔드에 상호 작용 모드로 진입한 이후에 좀 더 자세한 내용 설명을 요청(<strong>Please let me know more detail about it</strong>)하고 나오는 결괏값을 확인합니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/11.png" alt=" 옵션을 이용해서 상호 작용 모드로 진입하고 원하는 내용을 입력" tabindex="0" loading="lazy"><figcaption><code>--interactive</code> 옵션을 이용해서 상호 작용 모드로 진입하고 원하는 내용을 입력</figcaption></figure><p>처음 내용보다 훨씬 더 상세한 내용이 입력된 것을 확인할 수 있습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/12_QZuvVLx.png" alt="이번에는 현재 내용을 한국어로 설명해 달라고 입력합니다." tabindex="0" loading="lazy"><figcaption>이번에는 현재 내용을 <strong>한국어로 설명</strong>해 달라고 입력합니다.</figcaption></figure><p>일부 오류가 있긴 하지만 읽고 이해할 수 있는 수준의 한국어가 출력되는 것을 확인할 수 있습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/13.png" alt="마지막으로 현재 분석된 내용이 아닌 현재 클러스터의 버전을 확인해 달라는 문구(Could I get the current kubernetes version in this cluster?)를 입력합니다." tabindex="0" loading="lazy"><figcaption>마지막으로 현재 분석된 내용이 아닌 <strong>현재 클러스터의 버전을 확인해 달라는 문구</strong>(Could I get the current kubernetes version in this cluster?)를 입력합니다.</figcaption></figure><p>현재 발생한 문제와 연관이 없는 내용은 답변하지 않는 것을 확인할 수 있습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/14.png" alt="확인하고자 하는 내용을 완료했으니 를 입력해서 상호 작용 모드를 나옵니다." tabindex="0" loading="lazy"><figcaption>확인하고자 하는 내용을 완료했으니 <code>exit</code>를 입력해서 상호 작용 모드를 나옵니다.</figcaption></figure><p>google 말고 다른 AI는 어떻게 상호 작용되는지 확인하기 위해 cohere로 바꿔서 다시 테스트해 보겠습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/15.png" alt="AI만 바뀔 뿐 입력되는 구문 및 상황은 동일합니다." tabindex="0" loading="lazy"><figcaption>AI만 바뀔 뿐 입력되는 구문 및 상황은 동일합니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2515/16.png" alt="google과 다르게 대화하는 느낌으로 여러 가지 가능성에 대해서 설명해 주고 있습니다. 그렇다면 한국어로는 설명해 달라고 하면 어떻게 다를까요?" tabindex="0" loading="lazy"><figcaption>google과 다르게 대화하는 느낌으로 여러 가지 가능성에 대해서 설명해 주고 있습니다. 그렇다면 한국어로는 설명해 달라고 하면 어떻게 다를까요?</figcaption></figure><p>한국어로 설명이 나오지도 않고 한국어와 출력 코드가 안 맞는지 알 수 없는 내용만 출력됩니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/17.png" alt="마지막으로 현재 장애와 직접적인 연관이 없는 현재 쿠버네티스 버전을 알려달라는 요청을 합니다." tabindex="0" loading="lazy"><figcaption>마지막으로 현재 장애와 직접적인 연관이 없는 현재 쿠버네티스 버전을 알려달라는 요청을 합니다.</figcaption></figure><p>google 때와 다르게 이번에는 버전을 확인할 수 있는 명령어와 예시를 들어서 설명해 줍니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/18.png" alt="다음 진행을 위해서 를 치고 상호 작용 모드를 종료합니다." tabindex="0" loading="lazy"><figcaption>다음 진행을 위해서 <code>exit</code>를 치고 상호 작용 모드를 종료합니다.</figcaption></figure><p>이번 결과를 통해서 모델에 따라 답변이 변하는 것을 확인할 수 있고, 이에 따라 적합한 모델을 선택해야 하는 것이 더 원하는 답에 가까운 것을 얻을 수 있을 것이라는 부분을 예상할 수 있습니다. 이러한 변화 이외에 쿠버네티스 클러스터 분석 이외에 기능이 확장된 부분에 대해서 알아보겠습니다.</p><hr><h2 id="기능-확장" tabindex="-1"><a class="header-anchor" href="#기능-확장"><span>기능 확장</span></a></h2><figure><img src="https://yozm.wishket.com/media/news/2515/19.png" alt="v.0.3.28을 기준으로 다음과 같이 총 3개의 기능을 통합해서 확장할 수 있습니다." tabindex="0" loading="lazy"><figcaption>v.0.3.28을 기준으로 다음과 같이 총 3개의 기능을 통합해서 확장할 수 있습니다.</figcaption></figure><p>각 기능은 다음과 같습니다.</p><ul><li><code>trivy</code>: 쿠버네티스 클러스터의 보안 취약점 등을 알려줌</li><li><code>prometheus</code>: 프로메테우스가 설치되어 있는 환경에서 설정 등을 점검해줌</li><li><code>aws</code>: EKS와 같은 AWS의 리소스를 직접 분석해줌</li></ul><p>이 중에서 가장 간편하게 기능을 확인할 수 있는 <code>trivy</code>를 통해서 기능을 어떻게 확장하고 어떤 이점을 얻을 수 있는지 확인해 보겠습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/20_6DQ2d0Q.png" alt=" 옵션을 통해 를 우선 활성화시키겠습니다." tabindex="0" loading="lazy"><figcaption><code>integrations</code> 옵션을 통해 <code>trivy</code>를 우선 활성화시키겠습니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2515/21_aopySgO.png" alt="기능이 활성화 되었는지 확인하기 위해서  명령을 입력하고 integration된 와 를 확인합니다." tabindex="0" loading="lazy"><figcaption>기능이 활성화 되었는지 확인하기 위해서 <code>filters list</code> 명령을 입력하고 integration된 <code>VulnerabilityReport</code>와 <code>ConfigAuditReport</code>를 확인합니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2515/22_GtGf0tj.png" alt="활성화된 필터인 를 통해서 현재 클러스터의 취약점을 분석해 봅니다. 이를 위해서  을 추가합니다." tabindex="0" loading="lazy"><figcaption>활성화된 필터인 <code>VulnerabilityReport</code>를 통해서 현재 클러스터의 취약점을 분석해 봅니다. 이를 위해서 <code>--filter VulnerabilityReport</code> 을 추가합니다.</figcaption></figure><p>AI 제공자가 설정되어 있지 않아 해당 하는 취약점에 해당하는 CVE(Common Vulnerabilities and Exposures)만 출력되는 것을 확인할 수 있습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/23_GIpAfwO.png" alt="따라서 제공자를 google 그리고 cohere로 입력하여 어떤 결괏값이 나오는지 확인합니다." tabindex="0" loading="lazy"><figcaption>따라서 제공자를 google 그리고 cohere로 입력하여 어떤 결괏값이 나오는지 확인합니다.</figcaption></figure><p>이번에는 cohere를 통해서 어떤 결괏값이 나오는지 확인합니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/24_ZlMiebp.png" alt="AI 서비스 제공자의 차이로 분석하는 형태가 완전히 다른 것을 알 수 있습니다." tabindex="0" loading="lazy"><figcaption>AI 서비스 제공자의 차이로 분석하는 형태가 완전히 다른 것을 알 수 있습니다.</figcaption></figure><p>취약점 점검 이외에 trivy를 통해서 현재 구성 상태를 감사(Audit)하도록 하겠습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/25_nVDvzvl.png" alt="이때 사용되는 필터는  입니다. 일반적으로 취약점보다는 많은 내용이 출력됩니다." tabindex="0" loading="lazy"><figcaption>이때 사용되는 필터는 <code>ConfigAuditReport</code> 입니다. 일반적으로 취약점보다는 많은 내용이 출력됩니다.</figcaption></figure><p>분석된 내용을 기반으로 AI 제공자에게 설명을 요청했을 때 어떤 결과가 나오는지 확인해 보겠습니다.</p><p>우선 google로 진행하겠습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/26_vetXeCQ.png" alt="현재 배포된 이 사용하는 default 네임스페이스에  이 특정되어 있지 않다는 부분 외에 이게 어떤 의미를 가지는지, 어떻게 조치해야 하는지 등 많은 내용을 설명해 주고 있습니다." tabindex="0" loading="lazy"><figcaption>현재 배포된 <code>ReplicaSet</code>이 사용하는 default 네임스페이스에 <code>SECCOMP</code> 이 특정되어 있지 않다는 부분 외에 이게 어떤 의미를 가지는지, 어떻게 조치해야 하는지 등 많은 내용을 설명해 주고 있습니다.</figcaption></figure><p>cohere는 어떤 답변을 주는지 진행해 보겠습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2515/27.png" alt="cohere의 경우에는 trial 사용자가 1분에 5번 요청까지 처리하도록 허용하는데, 현재 44개의 요청이 진행되어야 하므로 진행 자체가 어려운 것을 확인할 수 있습니다." tabindex="0" loading="lazy"><figcaption>cohere의 경우에는 trial 사용자가 1분에 5번 요청까지 처리하도록 허용하는데, 현재 44개의 요청이 진행되어야 하므로 진행 자체가 어려운 것을 확인할 수 있습니다.</figcaption></figure><p>이와 같이 겨우 1년 밖에 지나지 않았지만 매우 많은 발전과 개선이 있었음을 알 수 있습니다. 지금까지는 외부 AI 서비스 제공자에게 데이터를 보내고 설명을 요청하는 방식으로 이루어졌습니다. 이와 같은 방식은 꽤 많은 기업에서 많이 우려하고 있는 방식일 수 있습니다.</p><hr>',50),E=l('<h2 id="공개된-ai-제공자를-사용하는-게-아닌-나만의-ai-제공자를-사용하는-법" tabindex="-1"><a class="header-anchor" href="#공개된-ai-제공자를-사용하는-게-아닌-나만의-ai-제공자를-사용하는-법"><span>공개된 AI 제공자를 사용하는 게 아닌 나만의 AI 제공자를 사용하는 법</span></a></h2><p>기업의 데이터라면 어떤 종류든 유출되는 것이 매우 민감한 문제일 수 있습니다. 이에 따라 k8sGPT도 <code>--anonymize</code> 옵션을 통해서 민감한 정보가 유출되지 않도록 지원하지만, 그럼에도 불구하고 공개된 AI 제공자를 사용하는 것 자체에 우려가 있습니다.</p><div class="hint-container info"><p class="hint-container-title">--anonymize</p><p>Anonymize data before sending it to the AI backend. This flag masks sensitive data, such as Kubernetes object names and labels, by replacing it with a key. However, please note that this flag does not currently apply to events.</p></div><p>따라서 기업 입장에서는 기업에서 접근하고 관리할 수 있는 AI 제공자를 구성하고 사용할 필요가 있는데, 이를 위해서 K8sGPT는 <code>localai</code>라는 제공자를 설정할 수 있습니다. 이름은 local이지만 이를 활용하면 본인의 AI 서비스를 제공하는 위치에 있는 API에 호출해서 결과를 가지고 오는 구조 이므로 꼭 local 국한되지 않습니다.</p><p>자세한 내용은 실습을 통해서 확인하겠습니다!</p><h3 id="사전-준비-확장된-기능-비활성화" tabindex="-1"><a class="header-anchor" href="#사전-준비-확장된-기능-비활성화"><span>(사전 준비) 확장된 기능 비활성화</span></a></h3><p>앞서 발행된 K8sGPT를 통한 쿠버네티스 AIOps의 가능성 1부에 이어, 2부를 진행한다면, 가장 먼저 필요한 작업은 기능을 확장했던 trivy를 비활성화 시키는 것입니다. v0.3.28까지는 기능을 확장한 경우 필터를 사용하지 않으면 정상적으로 사용하기 어렵습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2516/1.png" alt="기능을 확장한 경우에 를 실행하면 오류 발생" tabindex="0" loading="lazy"><figcaption>기능을 확장한 경우에 <code>k8sgpt analyze</code>를 실행하면 오류 발생</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2516/2.png" alt="를 실행 시  옵션을 추가하면 오류가 발생하지 않음" tabindex="0" loading="lazy"><figcaption><code>k8sgpt analyze</code>를 실행 시 <code>--filter</code> 옵션을 추가하면 오류가 발생하지 않음</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2516/3.png" alt="따라서 우선 활성화시킨 trivy를 비활성()화 시키겠습니다." tabindex="0" loading="lazy"><figcaption>따라서 우선 활성화시킨 trivy를 비활성(<code>deactivate</code>)화 시키겠습니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2516/4.png" alt="비활성화한 후에 현재 활성화된 기능이 있는지 확인합니다." tabindex="0" loading="lazy"><figcaption>비활성화한 후에 현재 활성화된 기능이 있는지 확인합니다.</figcaption></figure><hr><h2 id="llm-모델-구성-및-실행" tabindex="-1"><a class="header-anchor" href="#llm-모델-구성-및-실행"><span>LLM 모델 구성 및 실행</span></a></h2><p>K8sGPT에 나만의 AI 제공자를 구성하기 위해서는 우선 로컬에 LLM 모델이 구성 및 실행되어 있어야 합니다. 여기서 꼭 로컬일 필요는 없으나, K8sGPT가 요청할 수 있는 곳에 AI API가 동작하고 있어야 합니다. 이를 이해하기 위해서 간단히 K8sGPT가 어떻게 동작하는지를 다음의 그림으로 표현하였습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2516/image4.png" alt="K8sGPT가 쿠버네티스 클러스터를 분석하고 설명하는 과정" tabindex="0" loading="lazy"><figcaption>K8sGPT가 쿠버네티스 클러스터를 분석하고 설명하는 과정</figcaption></figure><p>지금까지의 과정에서는 공개된 AI 서비스 제공자(google, cohere 등)가 설명을 진행해줬고, 이를 공개된 AI 서비스 제공자가 아닌 내가 직접 구성한 AI 서비스 제공자로 바꾸는 것이 핵심입니다. 이를 위해 K8sGPT는 <code>localai</code>라는 제공자를 가지고 있으며, 해당 제공자는 API 주소을 입력하면 여기에 질의하여 해당 결과를 반환해 줍니다.</p><p>이 과정을 진행하기 위해서 가장 먼저 필요한 것은 AI 서비스 제공자를 만드는 것입니다. 이것은 매우 복잡할 수도 있으나, 간단한 테스트를 위해서 저희가 필요한건 <strong>AI 모델의 실행</strong>과 해당 모델에게 요청할 수 있는 <strong>API 주소</strong> 2가지 입니다.</p>',17),N={href:"https://ollama.com",target:"_blank",rel:"noopener noreferrer"},Q=e("code",null,"ollam",-1),F=l('<figure><img src="https://yozm.wishket.com/media/news/2516/image1.png" alt="우선 다음의 사이트를 통해서 현재 로컬 환경에 맞는 를 설치합니다." tabindex="0" loading="lazy"><figcaption>우선 다음의 <a href="https://ollama.com/download" target="_blank" rel="noopener noreferrer">사이트</a>를 통해서 현재 로컬 환경에 맞는 <code>ollama</code>를 설치합니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2516/5.png" alt="설치를 완료했다면 다음과 같이 를 실행할 수 있게 됩니다." tabindex="0" loading="lazy"><figcaption>설치를 완료했다면 다음과 같이 <code>ollam</code>를 실행할 수 있게 됩니다.</figcaption></figure><p><code>ollama</code>를 통해서 LLM를 실행하는 방법은 크게 2가지가 있습니다. (만약 도커에 익숙하시다면 유사한 느낌이 드실 겁니다.)</p><figure><img src="https://yozm.wishket.com/media/news/2516/6.png" alt="첫 번째는 모델을 내려받고 저장할 수 있는 입니다. pull 명령을 통해서 모델을 내려받는 과정은 매우 간단하고 쉽습니다." tabindex="0" loading="lazy"><figcaption>첫 번째는 모델을 내려받고 저장할 수 있는 <code>pull</code>입니다. pull 명령을 통해서 모델을 내려받는 과정은 매우 간단하고 쉽습니다.</figcaption></figure><p>내려받은 모델은 다음의 위치에 저장됩니다.</p>',5),Z=e("code",null,"~/.ollama/models",-1),j=e("code",null,"/usr/share/ollama/.ollama/models",-1),W=e("code",null,"C:\\Users\\<username>\\.ollama\\models",-1),X=l('<figure><img src="https://yozm.wishket.com/media/news/2516/7.png" alt="내려받은 모델은 를 통해서 확인이 가능합니다." tabindex="0" loading="lazy"><figcaption>내려받은 모델은 <code>ollama list</code>를 통해서 확인이 가능합니다.</figcaption></figure><p>내려받을 수 있는 대표 모델은 다음과 같습니다.</p><table><thead><tr><th style="text-align:center;">Model</th><th style="text-align:center;">Parameters</th><th style="text-align:center;">Size</th><th style="text-align:left;">Download</th></tr></thead><tbody><tr><td style="text-align:center;">Llama 2</td><td style="text-align:center;">7B</td><td style="text-align:center;">3.8GB</td><td style="text-align:left;"><code>ollama run llama2</code></td></tr><tr><td style="text-align:center;">Mistral</td><td style="text-align:center;">7B</td><td style="text-align:center;">4.1GB</td><td style="text-align:left;"><code>ollama run mistral</code></td></tr><tr><td style="text-align:center;">Dolphin Phi</td><td style="text-align:center;">2.7B</td><td style="text-align:center;">1.6GB</td><td style="text-align:left;"><code>ollama run dolphin-phi</code></td></tr><tr><td style="text-align:center;">Phi-2</td><td style="text-align:center;">2.7B</td><td style="text-align:center;">1.7GB</td><td style="text-align:left;"><code>ollama run phi</code></td></tr><tr><td style="text-align:center;">Neural Chat</td><td style="text-align:center;">7B</td><td style="text-align:center;">4.1GB</td><td style="text-align:left;"><code>ollama run neural-chat</code></td></tr><tr><td style="text-align:center;">Starling</td><td style="text-align:center;">7B</td><td style="text-align:center;">4.1GB</td><td style="text-align:left;"><code>ollama run starling-lm</code></td></tr><tr><td style="text-align:center;">Code Llama</td><td style="text-align:center;">7B</td><td style="text-align:center;">3.8GB</td><td style="text-align:left;"><code>ollama run codellama</code></td></tr><tr><td style="text-align:center;">Llama 2 Uncensored</td><td style="text-align:center;">7B</td><td style="text-align:center;">3.8GB</td><td style="text-align:left;"><code>ollama run llama2-uncensored</code></td></tr><tr><td style="text-align:center;">Llama 2 13B</td><td style="text-align:center;">13B</td><td style="text-align:center;">7.3GB</td><td style="text-align:left;"><code>ollama run llama2:13b</code></td></tr><tr><td style="text-align:center;">Llama 2 70B</td><td style="text-align:center;">70B</td><td style="text-align:center;">39GB</td><td style="text-align:left;"><code>ollama run llama2:70b</code></td></tr><tr><td style="text-align:center;">Orca Mini</td><td style="text-align:center;">3B</td><td style="text-align:center;">1.9GB</td><td style="text-align:left;"><code>ollama run orca-mini</code></td></tr><tr><td style="text-align:center;">Vicuna</td><td style="text-align:center;">7B</td><td style="text-align:center;">3.8GB</td><td style="text-align:left;"><code>ollama run vicuna</code></td></tr><tr><td style="text-align:center;">LLaVA</td><td style="text-align:center;">7B</td><td style="text-align:center;">4.5GB</td><td style="text-align:left;"><code>ollama run llava</code></td></tr><tr><td style="text-align:center;">Gemma</td><td style="text-align:center;">2B</td><td style="text-align:center;">1.4GB</td><td style="text-align:left;"><code>ollama run gemma:2b</code></td></tr><tr><td style="text-align:center;">Gemma</td><td style="text-align:center;">7B</td><td style="text-align:center;">4.8GB</td><td style="text-align:left;"><code>ollama run gemma:7b</code></td></tr></tbody></table>',3),q={href:"https://github.com/ollama/ollama?tab=readme-ov-file#model-library",target:"_blank",rel:"noopener noreferrer"},U=e("code",null,"ollama/ollama",-1),H=e("img",{src:"https://yozm.wishket.com/media/news/2516/image2.png",alt:'위의 모델 이외에도 <FontIcon icon="fas fa-globe"/>ollama 라이브러리 사이트를 통해서 검색도 가능합니다.',tabindex:"0",loading:"lazy"},null,-1),J={href:"https://ollama.com/library",target:"_blank",rel:"noopener noreferrer"},$=l('<p>두 번째는 모델을 내려받고 실행할 수 있는 <code>run</code>입니다. 이때 모델을 이미 내려받은 상태라면 내려받는 과정이 없이 바로 실행됩니다.</p><figure><img src="https://yozm.wishket.com/media/news/2516/8.png" alt="가장 작은 모델 중에 하나인 를 실행하겠습니다." tabindex="0" loading="lazy"><figcaption>가장 작은 모델 중에 하나인 <code>gemma:2b</code>를 실행하겠습니다.</figcaption></figure><p>이렇게 해서 모델이 실행되고 나면, openai 포맷으로 API 요청을 할 수 있습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2516/9.png" alt="테스트를 위해서 새로운 창을 열고  명령을 통해서 실행합니다." tabindex="0" loading="lazy"><figcaption>테스트를 위해서 새로운 창을 열고 <code>curl</code> 명령을 통해서 실행합니다.</figcaption></figure><p>API 요청을 할 수 있는 LLM 모델 구성, 그리고 실행이 매우 손쉽게 완료되었습니다.</p><hr><h2 id="k8sgpt에-localai-등록-후-실행" tabindex="-1"><a class="header-anchor" href="#k8sgpt에-localai-등록-후-실행"><span>K8sGPT에 <code>localai</code> 등록 후 실행</span></a></h2><p>localai에 등록하는 과정도 또한 매우 쉽습니다. (인증은 1부에서 소개한 다음의 <a href="https://docs.k8sgpt.ai/reference/providers/backend/" target="_blank" rel="noopener noreferrer">링크</a>를 참고하세요.)</p>',8),Y=e("img",{src:"https://yozm.wishket.com/media/news/2516/10.png",alt:'ollama를 통해서 실행된 모델에 접근하기 위한 주소인 <FontIcon icon="fas fa-globe"/>를 에 입력하고, ollama를 통해서 실행한 모델인  이름을 넣습니다.',tabindex:"0",loading:"lazy"},null,-1),ee=e("code",null,"http://localhost:11434/v1",-1),te=e("code",null,"--baseurl",-1),ie=e("code",null,"gemma:2b",-1),oe=l('<figure><img src="https://yozm.wishket.com/media/news/2516/11.png" alt="그리고 등록된 localai 서비스 제공자를 확인합니다." tabindex="0" loading="lazy"><figcaption>그리고 등록된 localai 서비스 제공자를 확인합니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2516/12.png" alt="이제 실제로 쿠버네티스 클러스터를 를 통해서 분석해 볼 차례입니다." tabindex="0" loading="lazy"><figcaption>이제 실제로 쿠버네티스 클러스터를 <code>localai</code>를 통해서 분석해 볼 차례입니다.</figcaption></figure><p>2B밖에 안되는 모델인 것을 고려했을 때 결과가 나쁘지 않게 나옵니다. 한국어로 답변을 줄 수 있는지 확인해 보겠습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2516/13.png" alt="한국어로는 출력되지 않고 약간 내용이 바뀐 것을 확인할 수 있습니다." tabindex="0" loading="lazy"><figcaption>한국어로는 출력되지 않고 약간 내용이 바뀐 것을 확인할 수 있습니다.</figcaption></figure><p>다른 모델은 어떤 답변을 제공하는지 확인해 보는 게 좋을 것 같습니다. 현재 실습 가능한 모델 중에 매개변수가 가장 큰 것 중에 하나인 <code>llama2:70b</code> 모델을 동작시키겠습니다.</p><figure><img src="https://yozm.wishket.com/media/news/2516/14.png" alt="모델을 바꾸기 위해서는 다른 모델을 우선 로드() 해야 합니다." tabindex="0" loading="lazy"><figcaption>모델을 바꾸기 위해서는 다른 모델을 우선 로드(<code>load</code>) 해야 합니다.</figcaption></figure><div class="hint-container tip"><p class="hint-container-title">load 시에 모델이 없는 경우는?</p><figure><img src="https://yozm.wishket.com/media/news/2516/15.png" alt="는 기존에 내려받아 두었기 때문에  명령이 실행되었던 것이고, 없는 모델을 load 한다면 다음과 같이 오류가 발생하게 됩니다." tabindex="0" loading="lazy"><figcaption><code>llama2:70b</code>는 기존에 내려받아 두었기 때문에 <code>load</code> 명령이 실행되었던 것이고, 없는 모델을 load 한다면 다음과 같이 오류가 발생하게 됩니다.</figcaption></figure></div><figure><img src="https://yozm.wishket.com/media/news/2516/16.png" alt="새로운 모델을 했다면 이번에는 에 를 다시 등록해야 합니다. 따라서 기존에 등록한 를 지우고 다시 등록합니다." tabindex="0" loading="lazy"><figcaption>새로운 모델을 <code>load</code>했다면 이번에는 <code>localai</code>에 <code>llama2:70b</code>를 다시 등록해야 합니다. 따라서 기존에 등록한 <code>localai</code>를 지우고 다시 등록합니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2516/17.png" alt="등록이 완료되었다면, 다시 에 설명을 요청합니다." tabindex="0" loading="lazy"><figcaption>등록이 완료되었다면, 다시 <code>localai</code>에 설명을 요청합니다.</figcaption></figure><p>한국어로도 물어봅니다.</p><figure><img src="https://yozm.wishket.com/media/news/2516/18.png" alt="내용이 약간 바뀌었을 뿐 한국어는 여전히 지원되지 않는 것을 확인할 수 있습니다." tabindex="0" loading="lazy"><figcaption>내용이 약간 바뀌었을 뿐 한국어는 여전히 지원되지 않는 것을 확인할 수 있습니다.</figcaption></figure><figure><img src="https://yozm.wishket.com/media/news/2516/19.png" alt="마지막으로 를 사용한 상호 작용 모드의 경우는 어떤지 확인해 보겠습니다." tabindex="0" loading="lazy"><figcaption>마지막으로 <code>localai</code>를 사용한 상호 작용 모드의 경우는 어떤지 확인해 보겠습니다.</figcaption></figure><p>이와 같이 한국어 지원은 다소 어려운 부분이 있지만, <code>localai</code>를 통해서 공개된 AI 서비스에 질의하지 않고도 현재 상황에 대해 설명을 받을 수 있는 것을 확인하였습니다.</p><p><code>ollama</code>를 통해서 실행된 모델 별로 얻을 수 있는 내용의 특장점은 추후에 다시 알아보기로 하겠습니다.</p><hr><h2 id="k8sgpt의-미래-전망" tabindex="-1"><a class="header-anchor" href="#k8sgpt의-미래-전망"><span>K8sGPT의 미래 전망</span></a></h2><p>K8sGPT는 현재 쿠버네티스 클러스터에 존재하는 여러 가지 문제 가능성을 분석해주는 훌륭한 도구입니다. 이러한 분석을 위해 다양한 AI 서비스 제공자를 선택할 수 있고, 또한 단순히 쿠버네티스 클러스터 분석뿐만 아니라 기능을 통합해서 확장할 수 있도록 지원하고 있습니다. 다만 상호 작용 모드에서 제한적으로 동작하고, 한국어와 같이 사용률이 높지 않은 경우에는 모델에서 지원하지 않는 경우가 많아서 사용에 약간 제약이 있을 수 있습니다.</p><p>그럼에도 불구하고 K8sGPT라는 프로젝트는 매우 빠르게 성장하고 있고, 커뮤니티의 의견을 적극적으로 받아들여 많은 기능들이 빠르게 추가되고 있습니다. 기업이 공개된 AI제공자를 사용함으로써 정보가 공개되는 것을 우려하는 부분도 localai를 통해서 해소할 수 있을 것으로 보이며, localai를 응용해 다양한 기업 환경에 맞는 모델을 직접 K8sGPT에서 사용하도록 설정할 수도 있을 것입니다.</p><p>따라서 K8sGPT는 현재 LLM의 추세와 맞물려 2024년 현재에 가장 인기 있는 주제 중에 하나가 될 것으로 보입니다.. 이대로만 발전한다면 상호 작용 모드 또한 현재와 같이 다소 제한이 있는 형태가 아닌, 사용자가 원하는 다양한 정보를 얻을 수 있는 형태로 변화할 것으로 예상됩니다.</p>',19);function ae(g,ne){const d=s("VPCard"),n=s("router-link"),c=s("SiteInfo"),r=s("RouteLink"),o=s("FontIcon");return y(),m("div",null,[e("h1",k,[e("a",z,[e("span",null,h(g.$frontmatter.title)+" 관련",1)])]),i(d,f(u({title:"Kubernetes > Article(s)",desc:"Article(s)",link:"/devops/k8s/articles/README.md",logo:"/images/ico-wind.svg",background:"rgba(10,10,10,0.2)"})),null,16),e("nav",b,[e("ul",null,[e("li",null,[i(n,{to:"#_1년간의-변화"},{default:a(()=>[t("1년간의 변화")]),_:1}),e("ul",null,[e("li",null,[i(n,{to:"#다양한-서비스-제공자"},{default:a(()=>[t("다양한 서비스 제공자")]),_:1})])])]),e("li",null,[i(n,{to:"#상호-작용-interactive-모드"},{default:a(()=>[t("상호 작용 (Interactive) 모드")]),_:1})]),e("li",null,[i(n,{to:"#기능-확장"},{default:a(()=>[t("기능 확장")]),_:1})]),e("li",null,[i(n,{to:"#공개된-ai-제공자를-사용하는-게-아닌-나만의-ai-제공자를-사용하는-법"},{default:a(()=>[t("공개된 AI 제공자를 사용하는 게 아닌 나만의 AI 제공자를 사용하는 법")]),_:1}),e("ul",null,[e("li",null,[i(n,{to:"#사전-준비-확장된-기능-비활성화"},{default:a(()=>[t("(사전 준비) 확장된 기능 비활성화")]),_:1})])])]),e("li",null,[i(n,{to:"#llm-모델-구성-및-실행"},{default:a(()=>[t("LLM 모델 구성 및 실행")]),_:1})]),e("li",null,[i(n,{to:"#k8sgpt에-localai-등록-후-실행"},{default:a(()=>[t("K8sGPT에 localai 등록 후 실행")]),_:1})]),e("li",null,[i(n,{to:"#k8sgpt의-미래-전망"},{default:a(()=>[t("K8sGPT의 미래 전망")]),_:1})])])]),_,i(c,{name:"로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기 (1) | 요즘IT",desc:"쿠버네티스는 계속 고도화되고 있어서 이를 분석하고 조치하는 것은 다양한 기반 지식을 필요로 합니다. 작년에 이어 올해도 인기 있는 인공지능(AI, Artificial Intelligence)을 이용해서 쿠버네티스를 분석하고 이에 맞는 조치를 할 수 있습니다.",url:"https://yozm.wishket.com/magazine/detail/2515/",logo:"https://yozm.wishket.com/static/renewal/img/global/gnb_yozmit.svg",preview:"https://yozm.wishket.com/media/news/2515/image4.png"}),x,e("p",null,[t("해당 프로젝트의 이름은 K8sGPT로, 이미 1차례 요즘IT에서 대략 1년 전 “"),i(r,{to:"/yozm.wishket.com/1990.html"},{default:a(()=>[t("ChatGPT로 쿠버네티스 관리하는 방법")]),_:1}),t("”이라는 글을 통해 소개된 적이 있습니다. 간단한 사용성에 대해서 소개하는 글이었는데, 이 글에서 그에 더해 추가적으로 설명하고자 하는 것은 다음과 같습니다.")]),I,e("figure",null,[A,e("figcaption",null,[t("K8sGPT 로고(출처: "),e("a",v,[i(o,{icon:"iconfont icon-github"}),G]),t(")")])]),P,e("figure",null,[T,e("figcaption",null,[t("구글클라우드플랫폼에서 제공하는 “"),e("a",L,[i(o,{icon:"iconfont icon-github"}),t("Online Boutine")]),t("” 애플리케이션(출처 :"),e("a",K,[i(o,{icon:"iconfont icon-github"}),t("Online Boutine")]),t(")")])]),B,e("div",M,[O,C,e("p",null,[t("인증은 다음의 "),e("a",R,[i(o,{icon:"fas fa-globe"}),t("링크")]),t("를 참고하세요")])]),e("p",null,[t("아마 저 뿐만 아니라 openai를 사용하는 많은 무료 사용자는 위와 같은 메시지를 자주 만나게 될 것입니다. 따라서 기본 제공자인 opanai가 아니라 다른 AI 제공자를 선택해야 하는데 가장 무난한 선택지는 google(제미나이)와 "),e("a",V,[i(o,{icon:"fas fa-globe"}),t("cohere")]),t("입니다. 각 제공자는 무료 사용자도 간단한 테스트를 할 수 있는 수준으로는 서비스를 제공합니다. 각 제공자에 대한 인증 설정은 계속 변화하기 때문에 위에서도 언급한 다음의 "),e("a",S,[i(o,{icon:"fas fa-globe"}),t("링크")]),t("를 참고하는 것이 좋습니다.")]),D,i(c,{name:"로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기 (2) | 요즘IT",desc:"앞서 K8sGPT를 통한 쿠버네티스 AIOps의 가능성 1부에서는 K8sGPT에서 지난 1년간 보여준 변화를 소개했습니다. 이번 글에서는 공개된 AI 제공자를 사용하는 게 아닌 '나만의 AI 제공자를 사용하는 법'을 소개하고 K8sGPT의 미래 전망에 대해 나름대로의 생각을 공유하도록 하겠습니다.",url:"https://yozm.wishket.com/magazine/detail/2516/",logo:"https://yozm.wishket.com/static/renewal/img/global/gnb_yozmit.svg",preview:"https://yozm.wishket.com/media/news/2515/image4.png"}),E,e("p",null,[t("이 2가지를 손쉽게 구현할 수 있는 도구로는 "),e("a",N,[i(o,{icon:"fas fa-globe"}),t("ollama")]),t("가 있습니다. "),Q,t("는 로컬 환경에 대규모 언어 모델(LLM, Large Language Models)을 손쉽게 구현할 수 있도록 도와줍니다.")]),F,e("ul",null,[e("li",null,[t("."),i(o,{icon:"fa-brands fa-apple"}),t("macOS: "),Z]),e("li",null,[t("."),i(o,{icon:"fa-brands fa-linux"}),t("Linux: "),j]),e("li",null,[t("."),i(o,{icon:"fa-brands fa-windows"}),t("Windows: "),W])]),X,e("blockquote",null,[e("p",null,[t("출처: "),e("a",q,[i(o,{icon:"iconfont icon-github"}),U])])]),e("figure",null,[H,e("figcaption",null,[t("위의 모델 이외에도 "),e("a",J,[i(o,{icon:"fas fa-globe"}),t("ollama 라이브러리 사이트")]),t("를 통해서 검색도 가능합니다.")])]),$,e("figure",null,[Y,e("figcaption",null,[t("ollama를 통해서 실행된 모델에 접근하기 위한 주소인 "),i(o,{icon:"fas fa-globe"}),ee,t("를 "),te,t("에 입력하고, ollama를 통해서 실행한 모델인 "),ie,t(" 이름을 넣습니다.")])]),oe])}const ce=p(w,[["render",ae],["__file","2515.html.vue"]]),ge=JSON.parse('{"path":"/yozm.wishket.com/2515.html","title":"로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기","lang":"ko-KR","frontmatter":{"lang":"ko-KR","title":"로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기","description":"Article(s) > 로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기","icon":"iconfont icon-k8s","category":["Kubernetes","VM","OpenAI","ChatGPT","Google","Cohere","LLM","Ollama"],"tag":["blog","yozm.wishket.com","kubernetes","google","google-ai-studio","cohere"],"head":[[{"meta":null},{"property":"og:title","content":"Article(s) > 로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기"},{"property":"og:description","content":"로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기"},{"property":"og:url","content":"https://chanhi2000.github.io/bookshelf/yozm.wishket.com/2515.html"}],["meta",{"property":"og:url","content":"https://chanhi2000.github.io/bookshelf/yozm.wishket.com/2515.html"}],["meta",{"property":"og:site_name","content":"📚Bookshelf"}],["meta",{"property":"og:title","content":"로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기"}],["meta",{"property":"og:description","content":"Article(s) > 로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://yozm.wishket.com/media/news/2515/image4.png"}],["meta",{"property":"og:locale","content":"ko-KR"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://yozm.wishket.com/media/news/2515/image4.png"}],["meta",{"name":"twitter:image:alt","content":"로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기"}],["meta",{"property":"article:tag","content":"blog"}],["meta",{"property":"article:tag","content":"yozm.wishket.com"}],["meta",{"property":"article:tag","content":"kubernetes"}],["meta",{"property":"article:tag","content":"google"}],["meta",{"property":"article:tag","content":"google-ai-studio"}],["meta",{"property":"article:tag","content":"cohere"}],["meta",{"property":"article:published_time","content":"2024-03-27T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"로컬 LLM에서 K8sGPT로 쿠버네티스 AIOps 실행하기\\",\\"image\\":[\\"https://github.com/k8sgpt-ai/k8sgpt\\",\\"https://yozm.wishket.com/media/news/2515/1_iru0ARX.png\\",\\"https://github.com/GoogleCloudPlatform/microservices-demo\\",\\"https://yozm.wishket.com/media/news/2515/2_NgxMTnp.png\\",\\"https://yozm.wishket.com/media/news/2515/3.png\\",\\"https://yozm.wishket.com/media/news/2515/4.png\\",\\"https://yozm.wishket.com/media/news/2515/5.png\\",\\"https://yozm.wishket.com/media/news/2515/6_2beWtS4.png\\",\\"https://yozm.wishket.com/media/news/2515/image3.png\\",\\"https://yozm.wishket.com/media/news/2515/image1.png\\",\\"https://yozm.wishket.com/media/news/2515/7.png\\",\\"https://yozm.wishket.com/media/news/2515/8.png\\",\\"https://yozm.wishket.com/media/news/2515/9_kI0xqpR.png\\",\\"https://yozm.wishket.com/media/news/2515/10.png\\",\\"https://yozm.wishket.com/media/news/2515/11.png\\",\\"https://yozm.wishket.com/media/news/2515/12_QZuvVLx.png\\",\\"https://yozm.wishket.com/media/news/2515/13.png\\",\\"https://yozm.wishket.com/media/news/2515/14.png\\",\\"https://yozm.wishket.com/media/news/2515/15.png\\",\\"https://yozm.wishket.com/media/news/2515/16.png\\",\\"https://yozm.wishket.com/media/news/2515/17.png\\",\\"https://yozm.wishket.com/media/news/2515/18.png\\",\\"https://yozm.wishket.com/media/news/2515/19.png\\",\\"https://yozm.wishket.com/media/news/2515/20_6DQ2d0Q.png\\",\\"https://yozm.wishket.com/media/news/2515/21_aopySgO.png\\",\\"https://yozm.wishket.com/media/news/2515/22_GtGf0tj.png\\",\\"https://yozm.wishket.com/media/news/2515/23_GIpAfwO.png\\",\\"https://yozm.wishket.com/media/news/2515/24_ZlMiebp.png\\",\\"https://yozm.wishket.com/media/news/2515/25_nVDvzvl.png\\",\\"https://yozm.wishket.com/media/news/2515/26_vetXeCQ.png\\",\\"https://yozm.wishket.com/media/news/2515/27.png\\",\\"https://yozm.wishket.com/media/news/2516/1.png\\",\\"https://yozm.wishket.com/media/news/2516/2.png\\",\\"https://yozm.wishket.com/media/news/2516/3.png\\",\\"https://yozm.wishket.com/media/news/2516/4.png\\",\\"https://yozm.wishket.com/media/news/2516/image4.png\\",\\"https://ollama.com/download\\",\\"https://yozm.wishket.com/media/news/2516/5.png\\",\\"https://yozm.wishket.com/media/news/2516/6.png\\",\\"https://yozm.wishket.com/media/news/2516/7.png\\",\\"https://ollama.com/library\\",\\"https://yozm.wishket.com/media/news/2516/8.png\\",\\"https://yozm.wishket.com/media/news/2516/9.png\\",\\"https://yozm.wishket.com/media/news/2516/10.png\\",\\"https://yozm.wishket.com/media/news/2516/11.png\\",\\"https://yozm.wishket.com/media/news/2516/12.png\\",\\"https://yozm.wishket.com/media/news/2516/13.png\\",\\"https://yozm.wishket.com/media/news/2516/14.png\\",\\"https://yozm.wishket.com/media/news/2516/15.png\\",\\"https://yozm.wishket.com/media/news/2516/16.png\\",\\"https://yozm.wishket.com/media/news/2516/17.png\\",\\"https://yozm.wishket.com/media/news/2516/18.png\\",\\"https://yozm.wishket.com/media/news/2516/19.png\\"],\\"datePublished\\":\\"2024-03-27T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[]}"]],"prev":"/devops/k8s/articles/README.md","date":"2024-03-27T00:00:00.000Z","isOriginal":false,"cover":"https://yozm.wishket.com/media/news/2515/image4.png"},"headers":[{"level":2,"title":"1년간의 변화","slug":"_1년간의-변화","link":"#_1년간의-변화","children":[{"level":3,"title":"다양한 서비스 제공자","slug":"다양한-서비스-제공자","link":"#다양한-서비스-제공자","children":[]}]},{"level":2,"title":"상호 작용 (Interactive) 모드","slug":"상호-작용-interactive-모드","link":"#상호-작용-interactive-모드","children":[]},{"level":2,"title":"기능 확장","slug":"기능-확장","link":"#기능-확장","children":[]},{"level":2,"title":"공개된 AI 제공자를 사용하는 게 아닌 나만의 AI 제공자를 사용하는 법","slug":"공개된-ai-제공자를-사용하는-게-아닌-나만의-ai-제공자를-사용하는-법","link":"#공개된-ai-제공자를-사용하는-게-아닌-나만의-ai-제공자를-사용하는-법","children":[{"level":3,"title":"(사전 준비) 확장된 기능 비활성화","slug":"사전-준비-확장된-기능-비활성화","link":"#사전-준비-확장된-기능-비활성화","children":[]}]},{"level":2,"title":"LLM 모델 구성 및 실행","slug":"llm-모델-구성-및-실행","link":"#llm-모델-구성-및-실행","children":[]},{"level":2,"title":"K8sGPT에 localai 등록 후 실행","slug":"k8sgpt에-localai-등록-후-실행","link":"#k8sgpt에-localai-등록-후-실행","children":[]},{"level":2,"title":"K8sGPT의 미래 전망","slug":"k8sgpt의-미래-전망","link":"#k8sgpt의-미래-전망","children":[]}],"git":{"contributors":[{"name":"chanhi2000","email":"chanhi2000@gmail.com","commits":2}]},"readingTime":{"minutes":3.15,"words":946},"filePathRelative":"yozm.wishket.com/2515.md","localizedDate":"2024년 3월 27일","excerpt":"\\n"}');export{ce as comp,ge as data};
